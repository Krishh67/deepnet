import os
import io
import json
import tempfile
from pathlib import Path

import numpy as np
import librosa
from scipy.signal import butter, filtfilt

# Heavy imports moved to lazy loading
# import tensorflow asimport tensorflow_hub as hub
# import google.generativeai as genai

from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

from dotenv import load_dotenv

# Torch imports for CNN model
import torch
import torch.nn as nn
import torch.nn.functional as F

# NOTE: matplotlib, tensorflow, and yamnet loaded lazily to avoid startup crash

# =========================
# ENV + APP SETUP
# =========================
load_dotenv()
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
if not GEMINI_API_KEY:
    raise RuntimeError("GEMINI_API_KEY not set")

app = FastAPI(title="OceanGuard â€“ Hybrid Seismic Detection API (3-Layer)")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# =========================
# RESPONSE MODEL
# =========================
class AnalysisResult(BaseModel):
    detection_type: str
    confidence: int
    tsunami_risk: str
    ai_description: str

class SeismicPrediction(BaseModel):
    detection_type: str  # "Seismic Event" or "Background Noise"
    confidence: float  # 0-100
    model_accuracy: float  # 97.0
    description: str

# =========================
# CNN MODEL DEFINITION
# =========================
class SeismicCNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv1d(3, 64, 7, padding=3)
        self.conv2 = nn.Conv1d(64, 128, 5, padding=2)
        self.conv3 = nn.Conv1d(128, 256, 3, padding=1)
        self.conv4 = nn.Conv1d(256, 512, 3, padding=1)
        self.pool = nn.MaxPool1d(2)
        self.gap = nn.AdaptiveAvgPool1d(1)
        self.fc = nn.Linear(512, 1)
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = self.pool(F.relu(self.conv3(x)))
        x = self.pool(F.relu(self.conv4(x)))
        x = self.gap(x).squeeze(-1)
        x = self.dropout(x)
        return torch.sigmoid(self.fc(x))

# =========================
# GLOBAL YAMNET (loaded once on first use)
# =========================
_yamnet = None
_CLASS_NAMES = None
_seismic_cnn = None

def get_seismic_cnn():
    """Lazy load Seismic CNN model"""
    global _seismic_cnn
    if _seismic_cnn is None:
        print("ğŸ”„ Loading Seismic CNN model (first time)...")
        device = "cuda" if torch.cuda.is_available() else "cpu"
        _seismic_cnn = SeismicCNN().to(device)
        model_path = "backend/seismic_cnn.pth"
        _seismic_cnn.load_state_dict(torch.load(model_path, map_location=device))
        _seismic_cnn.eval()
        print(f"âœ… Seismic CNN loaded on {device}!")
    return _seismic_cnn

def get_yamnet():
    """Lazy load YAMNet model"""
    global _yamnet, _CLASS_NAMES
    if _yamnet is None:
        print("ğŸ”„ Loading YAMNet model (first time)...")
        import tensorflow_hub as hub
        _yamnet = hub.load("https://tfhub.dev/google/yamnet/1")
        class_map = _yamnet.class_map_path().numpy().decode("utf-8")
        _CLASS_NAMES = [l.strip() for l in open(class_map)]
        print("âœ… YAMNet loaded!")
    return _yamnet, _CLASS_NAMES

MARINE_KEYS = ["whale", "dolphin", "seal", "animal", "fish", "orca", "porpoise"]

# =========================
# UTILS
# =========================
def bandpass(data, low, high, sr, order=4):
    nyq = 0.5 * sr
    b, a = butter(order, [low/nyq, high/nyq], btype="band")
    return filtfilt(b, a, data)

# =========================
# CNN PREPROCESSING UTILS
# =========================
def fix_length(x, T=2000):
    """Fix array length to match model input requirement"""
    if x.shape[1] >= T:
        return x[:, :T]
    return np.pad(x, ((0,0),(0,T - x.shape[1])))

def normalize(x):
    """Normalize audio data"""
    return (x - x.mean()) / (x.std() + 1e-6)

def prepare_cnn_input(audio_path):
    """
    Prepare audio file for CNN model input.
    Simulates 3-channel seismic data from mono/stereo audio.
    Returns: torch tensor of shape (1, 3, 2000)
    """
    # Load audio
    y, sr = librosa.load(audio_path, sr=200, mono=True)
    
    # Simulate 3 channels (Z, N, E) by applying different filters
    # This is a simplification - in real seismic data, these are separate sensors
    y_Z = bandpass(y, 1, 20, sr)  # Vertical component
    y_N = bandpass(y, 2, 15, sr)  # North component  
    y_E = bandpass(y, 3, 18, sr)  # East component
    
    # Stack into 3-channel format
    x = np.stack([y_Z, y_N, y_E])
    
    # Normalize and fix length
    x = normalize(fix_length(x))
    
    # Convert to torch tensor
    device = "cuda" if torch.cuda.is_available() else "cpu"
    return torch.tensor(x, dtype=torch.float32).unsqueeze(0).to(device)

def generate_spectrogram(audio_path: str) -> bytes:
    """Generate spectrogram with lazy matplotlib import"""
    import matplotlib
    matplotlib.use('Agg')
    import matplotlib.pyplot as plt
    import librosa.display
    
    y, sr = librosa.load(audio_path, sr=200)
    S = librosa.stft(y, n_fft=256)
    S_db = librosa.amplitude_to_db(np.abs(S), ref=np.max)

    plt.figure(figsize=(10, 4))
    librosa.display.specshow(S_db, sr=sr, x_axis="time", y_axis="hz")
    plt.ylim(0, 50)
    plt.colorbar()
    plt.title("Filtered Spectrogram (0â€“50 Hz)")
    plt.tight_layout()

    buf = io.BytesIO()
    plt.savefig(buf, format="png", dpi=100)
    plt.close()
    buf.seek(0)
    return buf.read()

# =========================
# LAYER 1 â€“ PHYSICS GATE
# =========================
def seismic_candidate(audio_path):
    """
    Physics-based earthquake detection
    Returns: (is_detected, confidence, duration)
    """
    y, sr = librosa.load(audio_path, sr=200, mono=True)
    duration = librosa.get_duration(y=y, sr=sr)

    y = bandpass(y, 1, 20, sr)

    win = int(sr * 2)
    rms = np.array([
        np.sqrt(np.mean(y[i:i+win]**2))
        for i in range(0, len(y)-win, win)
    ])

    rms = rms / np.max(rms)
    detected = (rms.max() > 0.6) and (np.sum(rms > 0.4) > 4)

    return detected, float(rms.max()), duration

# =========================
# LAYER 2 â€“ YAMNET (MARINE?)
# =========================
def is_marine(audio_path, threshold=0.25):
    """
    YAMNet-based marine life detection
    Returns: (is_marine, confidence)
    """
    import tensorflow as tf
    
    yamnet, CLASS_NAMES = get_yamnet()
    
    y, sr = librosa.load(audio_path, sr=16000, mono=True)
    scores, _, _ = yamnet(tf.convert_to_tensor(y, tf.float32))
    mean_scores = tf.reduce_mean(scores, axis=0).numpy()

    marine_score = 0.0
    for i, label in enumerate(CLASS_NAMES):
        if any(k in label.lower() for k in MARINE_KEYS):
            marine_score += mean_scores[i]

    return marine_score > threshold, marine_score

# =========================
# GEMINI AI CLASSIFIER
# =========================
def gemini_classifier(spectrogram, audio_bytes, ext, rms_conf, duration):
    """
    Gemini AI comprehensive classification with physics features
    Classifies: Earthquake, Explosion, Marine Life, or Ambient Noise
    """
    import google.generativeai as genai
    genai.configure(api_key=GEMINI_API_KEY)
    
    prompt = f"""
You are an expert underwater acoustic analyst. Analyze this audio event using the spectrogram, raw audio, and physics-based features.

**Physics Features:**
- RMS Confidence: {rms_conf:.2f} (0-1 scale, energy level)
- Duration: {duration:.2f} seconds

**Classification Categories:**
1. **Earthquake** - Gradual onset, long duration (>10s), sustained low-frequency energy (1-20 Hz), RMS typically >0.6
2. **Explosion** - Sudden onset, short duration (<5s), broadband spike, high RMS peak
3. **Marine Life** - Biological patterns (clicks, whistles, calls), irregular patterns, moderate duration
4. **Ambient Noise** - Low RMS (<0.4), no clear structure, random fluctuations

**Analysis Instructions:**
- Examine the spectrogram for frequency patterns and energy distribution
- Listen to the audio for onset characteristics (gradual vs sudden)
- Use RMS and duration to validate your hypothesis
- Consider the underwater acoustic environment

**Respond ONLY with valid JSON:**
{{
  "final_type": "Earthquake" | "Explosion" | "Marine Life" | "Ambient Noise",
  "confidence": <0-100>,
  "reason": "<2-3 sentences explaining: what you observed in spectrogram, audio characteristics, and how physics features support the classification>"
}}
"""

    model = genai.GenerativeModel("gemini-2.0-flash-exp")
    mime = "audio/wav" if ext == ".wav" else "audio/mpeg"

    response = model.generate_content([
        {"mime_type": "image/png", "data": spectrogram},
        {"mime_type": mime, "data": audio_bytes},
        prompt
    ])

    text = response.text.strip().replace("```json", "").replace("```", "").strip()
    
    try:
        return json.loads(text)
    except json.JSONDecodeError as e:
        print(f"  âš ï¸ JSON parsing error: {e}")
        print(f"  Raw response: {text[:200]}...")
        # Fallback response
        return {
            "final_type": "Earthquake" if rms_conf > 0.6 else "Ambient Noise",
            "confidence": int(rms_conf * 100),
            "reason": f"AI classification failed (JSON parse error). Fallback based on RMS: {rms_conf:.2f}"
        }

# =========================
# API
# =========================
@app.get("/")
async def root():
    return {"status": "ok", "message": "Hybrid 3-Layer API: Physics + YAMNet + Gemini"}

@app.post("/predict-seismic", response_model=SeismicPrediction)
async def predict_seismic(file: UploadFile = File(...)):
    """
    CNN-based seismic event detection (97% accuracy)
    Classifies audio as: Seismic Event or Background Noise
    """
    
    if Path(file.filename).suffix.lower() not in [".wav", ".mp3", ".m4a"]:
        raise HTTPException(400, "Invalid file type. Please upload WAV, MP3, or M4A")

    with tempfile.NamedTemporaryFile(delete=False, suffix=Path(file.filename).suffix) as tmp:
        tmp.write(await file.read())
        path = tmp.name

    print(f"\nğŸµ CNN Analysis: {file.filename}")
    
    try:
        # Load model
        model = get_seismic_cnn()
        
        # Preprocess audio
        print("  [1/2] Preprocessing audio...")
        x = prepare_cnn_input(path)
        
        # Run inference
        print("  [2/2] Running CNN inference...")
        with torch.no_grad():
            prediction = model(x).item()
        
        os.unlink(path)
        
        # Determine classification
        is_event = prediction > 0.5
        confidence = prediction * 100 if is_event else (1 - prediction) * 100
        
        detection_type = "Seismic Event" if is_event else "Background Noise"
        description = (
            f"Deep learning model detected a seismic event with high confidence. "
            f"The 1D CNN analyzed the 3-channel waveform and identified characteristic "
            f"patterns associated with earthquake activity."
            if is_event else
            f"The CNN model classified this audio as background noise. "
            f"No significant seismic patterns were detected in the waveform data."
        )
        
        print(f"  âœ… Result: {detection_type} ({confidence:.1f}% confidence)")
        
        return SeismicPrediction(
            detection_type=detection_type,
            confidence=round(confidence, 2),
            model_accuracy=97.0,
            description=description
        )
    
    except Exception as e:
        if os.path.exists(path):
            os.unlink(path)
        print(f"  âŒ Error: {str(e)}")
        raise HTTPException(500, f"Prediction failed: {str(e)}")

@app.post("/analyze", response_model=AnalysisResult)
async def analyze(file: UploadFile = File(...)):
    """
    Gemini-First Classification with Physics Features:
    - Extracts physics features (RMS, duration) from audio
    - Generates spectrogram for visual analysis
    - Uses Gemini AI with multimodal input (audio + image + physics data)
    - Classifies: Earthquake, Explosion, Marine Life, or Ambient Noise
    """
    
    if Path(file.filename).suffix.lower() not in [".wav", ".mp3", ".m4a"]:
        raise HTTPException(400, "Invalid file type")

    with tempfile.NamedTemporaryFile(delete=False, suffix=Path(file.filename).suffix) as tmp:
        tmp.write(await file.read())
        path = tmp.name

    print(f"\nğŸµ Analyzing: {file.filename}")
    
    try:
        # Step 1: Extract physics features
        print("  [1/3] Extracting physics features (RMS, duration)...")
        seismic, rms_conf, duration = seismic_candidate(path)
        print(f"        RMS: {rms_conf:.3f}, Duration: {duration:.2f}s")
        
        # Step 2: Generate spectrogram
        print("  [2/3] Generating spectrogram...")
        spectrogram = generate_spectrogram(path)
        
        # Step 3: Load audio bytes
        print("  [3/3] Running Gemini AI classification...")
        with open(path, "rb") as f:
            audio_bytes = f.read()
        
        # Clean up temp file
        os.unlink(path)
        
        # Gemini AI Classification
        gem = gemini_classifier(
            spectrogram=spectrogram,
            audio_bytes=audio_bytes,
            ext=Path(file.filename).suffix.lower(),
            rms_conf=rms_conf,
            duration=duration
        )
        
        # Determine tsunami risk based on classification
        detection = gem["final_type"]
        if detection == "Earthquake" and rms_conf > 0.8:
            tsunami_risk = "High"
        elif detection == "Earthquake" and rms_conf > 0.6:
            tsunami_risk = "Medium"
        elif detection == "Explosion":
            tsunami_risk = "Low"
        else:
            tsunami_risk = "Low"
        
        print(f"  âœ… Result: {detection} ({gem['confidence']}% confidence)")
        print(f"     Tsunami Risk: {tsunami_risk}")
        
        return AnalysisResult(
            detection_type=detection,
            confidence=gem["confidence"],
            tsunami_risk=tsunami_risk,
            ai_description=gem["reason"]
        )
    
    except Exception as e:
        if os.path.exists(path):
            os.unlink(path)
        print(f"  âŒ Error: {str(e)}")
        raise HTTPException(500, f"Analysis failed: {str(e)}")

# =========================
# RUN
# =========================
if __name__ == "__main__":
    import uvicorn
    print("ğŸŒŠ OceanGuard Hybrid API")
    print("ğŸ“Š 3-Layer Classification:")
    print("   Layer 1: Physics (Seismic detection)")
    print("   Layer 2: YAMNet (Marine life)")
    print("   Layer 3: Gemini AI (Earthquake vs Explosion)")
    print("\nğŸš€ Starting on port 8002...")
    uvicorn.run(app, host="0.0.0.0", port=8000)
